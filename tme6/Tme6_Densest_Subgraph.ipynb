{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME 6 - Densest Subgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour la construction de la liste d'adjacence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# On trie les edges dans un nouveau fichier sorted_data\n",
    "# Pour chaque edge, on met le point d'indice plus petit en debut de ligne\n",
    "def clear_dataset(file,source,separator):\n",
    "    graph = open(file+source, \"r\")\n",
    "    sorted_graph = open(file+\"sorted_data\", \"w+\")\n",
    "    for e in graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        e = e.rstrip(\"\\n\")\n",
    "        array_e = e.split(separator)\n",
    "        if(int(array_e[0]) > int(array_e[1])):\n",
    "            array_e[0],array_e[1] = array_e[1],array_e[0]\n",
    "            str_e = ' '.join(array_e)\n",
    "            sorted_graph.write(str_e + \"\\n\")\n",
    "            continue\n",
    "        str_e = ' '.join(array_e)\n",
    "        sorted_graph.write(str_e + \"\\n\")\n",
    "\n",
    "    sorted_graph.close()\n",
    "    graph.close()\n",
    "\n",
    "    # A partir de sorted_data\n",
    "    # on cree un fichier cleaned_data contenant les edges sans doublon\n",
    "    sorted_graph = open(file+\"sorted_data\", \"r\")\n",
    "    cleaned_graph = open(file+\"cleaned_data\", \"w+\")\n",
    "    for e in sorted_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        e = e.rstrip(\"\\n\")\n",
    "        indice_point = e.split(\" \")\n",
    "        if int(indice_point[0]) == int(indice_point[1]):\n",
    "            continue\n",
    "        if not(e in cleaned_graph):\n",
    "            cleaned_graph.write(str(e) + \"\\n\")\n",
    "    cleaned_graph.close()\n",
    "    sorted_graph.close()\n",
    "    \n",
    "\n",
    "# Dans le graph, trouver le sommet d'indice maximum\n",
    "def indice_max(file):\n",
    "    cleaned_graph = open(file+\"cleaned_data\", \"r\")\n",
    "    max_int = -1\n",
    "    for e in cleaned_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        e = e.rstrip(\"\\n\")\n",
    "        indice_point = e.split(\" \")\n",
    "        if int(indice_point[0])>max_int:\n",
    "            max_int = int(indice_point[0])\n",
    "        if int(indice_point[1])>max_int:\n",
    "            max_int = int(indice_point[1])\n",
    "    cleaned_graph.close()\n",
    "    return max_int\n",
    "\n",
    "# Renvoi une structure de données : liste d'adjacence\n",
    "def liste_adjacence(file):\n",
    "    cleaned_graph = open(file+\"cleaned_data\", \"r\")\n",
    "    map_sommet_voisin_no_filtred = dict()\n",
    "    for i in range(indice_max(file)+1):\n",
    "        map_sommet_voisin_no_filtred[i] = list()\n",
    "    for e in cleaned_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        edge_str = e.rstrip(\"\\n\")\n",
    "        edge = edge_str.split(\" \")\n",
    "        if(not(int(edge[1]) in map_sommet_voisin_no_filtred[int(edge[0])])):\n",
    "            map_sommet_voisin_no_filtred[int(edge[0])].append(int(edge[1]))\n",
    "        if(not(int(edge[0]) in map_sommet_voisin_no_filtred[int(edge[1])])):\n",
    "            map_sommet_voisin_no_filtred[int(edge[1])].append(int(edge[0]))\n",
    "    cleaned_graph.close()\n",
    "    \n",
    "    # On filtre notre map en enlevant les sommets sans voisins\n",
    "    map_sommet_voisin = dict()\n",
    "    for k in map_sommet_voisin_no_filtred.keys():\n",
    "        if len(map_sommet_voisin_no_filtred[k]) == 0:\n",
    "            continue\n",
    "        map_sommet_voisin[k] = map_sommet_voisin_no_filtred[k]\n",
    "    return map_sommet_voisin\n",
    "\n",
    "# Même fonction que indice_max mais prend directement un fichier clean\n",
    "def indice_max_from_clean_file(file):\n",
    "    cleaned_graph = open(file, \"r\")\n",
    "    max_int = -1\n",
    "    for e in cleaned_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        e = e.rstrip(\"\\n\")\n",
    "        indice_point = e.split(\"\\t\")\n",
    "        if int(indice_point[0])>max_int:\n",
    "            max_int = int(indice_point[0])\n",
    "        if int(indice_point[1])>max_int:\n",
    "            max_int = int(indice_point[1])\n",
    "    cleaned_graph.close()\n",
    "    return max_int\n",
    "\n",
    "# Même fonction que liste_adjacence mais prend directement un fichier clean\n",
    "def liste_adjacence_from_clean_file(file):\n",
    "    cleaned_graph = open(file, \"r\")\n",
    "    map_sommet_voisin_no_filtred = dict()\n",
    "    for i in range(indice_max_from_clean_file(file)+1):\n",
    "        map_sommet_voisin_no_filtred[i] = list()\n",
    "    for e in cleaned_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        edge_str = e.rstrip(\"\\n\")\n",
    "        edge = edge_str.split(\"\\t\")\n",
    "        if(not(int(edge[1]) in map_sommet_voisin_no_filtred[int(edge[0])])):\n",
    "            map_sommet_voisin_no_filtred[int(edge[0])].append(int(edge[1]))\n",
    "        if(not(int(edge[0]) in map_sommet_voisin_no_filtred[int(edge[1])])):\n",
    "            map_sommet_voisin_no_filtred[int(edge[1])].append(int(edge[0]))\n",
    "    cleaned_graph.close()\n",
    "    map_sommet_voisin = dict()\n",
    "    for k in map_sommet_voisin_no_filtred.keys():\n",
    "        if len(map_sommet_voisin_no_filtred[k]) == 0:\n",
    "            continue\n",
    "        map_sommet_voisin[k] = map_sommet_voisin_no_filtred[k]\n",
    "    return map_sommet_voisin\n",
    "\n",
    "def nb_edge(file):\n",
    "    nb_edge = 0\n",
    "    graph = open(file, \"r\")\n",
    "    for e in graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        nb_edge = nb_edge + 1\n",
    "    return nb_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_dataset(\"graph/email/\",\"email-Eu-core.txt\",\" \")\n",
    "email = liste_adjacence(\"graph/email/\")\n",
    "\n",
    "#clear_dataset(\"graph/amazon/\",\"com-amazon.ungraph.txt\",\"\\t\")\n",
    "#amazon = liste_adjacence(\"graph/amazon/\")\n",
    "\n",
    "#livreJournal = liste_adjacence_from_clean_file(\"graph/lj/com-lj.ungraph-clean.txt\")\n",
    "\n",
    "#orkut = liste_adjacence_from_clean_file(\"graph/orkut/com-orkut.ungraph-clean.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHeap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinHeap:\n",
    "    def __init__(self):\n",
    "        self.heapList = []\n",
    "        self.currentSize = 0\n",
    " \n",
    "    def percUp(self,i,map_index_tas):\n",
    "        while ((i+1 // 2)  > 0):\n",
    "            if self.heapList[i][1] < self.heapList[(i - 1)// 2][1]:\n",
    "                tmp = self.heapList[(i-1) // 2]\n",
    "                self.heapList[(i-1) // 2] = self.heapList[i]\n",
    "                self.heapList[i] = tmp\n",
    "                if(map_index_tas):\n",
    "                    tmp_ind = map_index_tas[self.heapList[(i-1) // 2][0]]\n",
    "                    map_index_tas[self.heapList[(i - 1)// 2][0]] = (i - 1)// 2\n",
    "                    map_index_tas[self.heapList[i][0]] = tmp_ind\n",
    "            i = (i-1)//2\n",
    "    \n",
    "    def insert(self,k,map_index_tas):\n",
    "        self.heapList.append(k)\n",
    "        self.currentSize = self.currentSize + 1\n",
    "        self.percUp(self.currentSize-1,map_index_tas)\n",
    "    \n",
    "    def percDown(self,i,map_index_tas):\n",
    "        while (i * 2) <= self.currentSize-1 :\n",
    "            mc = self.minChild(i)\n",
    "            if self.heapList[i][1] > self.heapList[mc][1]:\n",
    "                tmp = self.heapList[i]\n",
    "                self.heapList[i] = self.heapList[mc]\n",
    "                self.heapList[mc] = tmp\n",
    "                if(map_index_tas):\n",
    "                    tmp_ind = map_index_tas[self.heapList[i][0]]\n",
    "                    map_index_tas[self.heapList[i][0]] = i\n",
    "                    map_index_tas[self.heapList[mc][0]] = tmp_ind\n",
    "            i = mc\n",
    "            if i == 0:\n",
    "                break\n",
    "\n",
    "    def minChild(self,i):\n",
    "        if i * 2 + 1 > self.currentSize-1:\n",
    "            return i * 2\n",
    "        else:\n",
    "            if self.heapList[i*2][1] < self.heapList[i*2+1][1]:\n",
    "                return i * 2\n",
    "            else:\n",
    "                return i * 2 + 1\n",
    "    \n",
    "    def delMin(self,map_index_tas):\n",
    "        retval = self.heapList[0]\n",
    "        self.heapList[0] = self.heapList[self.currentSize-1]\n",
    "        self.currentSize = self.currentSize - 1\n",
    "        self.heapList.pop()\n",
    "        if self.currentSize > 0:\n",
    "            del map_index_tas[self.heapList[0][0]]\n",
    "        self.percDown(0,map_index_tas)\n",
    "        return retval\n",
    "    \n",
    "    def buildHeap(self,alist,map_index_tas):\n",
    "        i = len(alist) // 2\n",
    "        self.currentSize = len(alist)\n",
    "        self.heapList = [] + alist[:]\n",
    "        while (i > 0):\n",
    "            self.percDown(i,map_index_tas)\n",
    "            i = i - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : k-core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import copy\n",
    "\n",
    "def core_decomposition(graph):\n",
    "    c = 0\n",
    "    n = len(list(graph.keys())) + 1\n",
    "    subgraph_order = dict()\n",
    "    tas = BinHeap()\n",
    "    map_index_tas = dict()\n",
    "    visited = dict()\n",
    "    \n",
    "    for s in list(graph.keys()):\n",
    "        tas.insert((s,len(graph[s])),map_index_tas)\n",
    "        visited[s] = False\n",
    "\n",
    "    for i, t in enumerate(tas.heapList):\n",
    "        map_index_tas[t[0]] = i\n",
    "        \n",
    "    while(len(tas.heapList) > 0):\n",
    "        v = tas.heapList[0]\n",
    "        c = max(c,v[1])\n",
    "        \n",
    "        for v_voisin in graph[v[0]]:\n",
    "            if(visited[v_voisin] == True):\n",
    "                continue\n",
    "            v_voisin = int(v_voisin)\n",
    "            lst = list(tas.heapList[map_index_tas[v_voisin]])\n",
    "            lst[1] = tas.heapList[map_index_tas[v_voisin]][1] - 1\n",
    "            t = tuple(lst)\n",
    "            tas.heapList[map_index_tas[v_voisin]] = t\n",
    "            tas.percUp(map_index_tas[v_voisin],map_index_tas)\n",
    "        tas.delMin(map_index_tas)\n",
    "        visited[v[0]] = True\n",
    "        subgraph_order[v[0]] = n\n",
    "        n = n - 1\n",
    "    print(c)\n",
    "    return subgraph_order\n",
    "\n",
    "def get_subgraph_ssj(subgraph_order):\n",
    "    subgraph = sorted(subgraph_order.items(), key=lambda kv: kv[1])\n",
    "    return subgraph\n",
    "\n",
    "def get_density(graph, subgraph):\n",
    "    nb_edge = 0\n",
    "    # délation logique\n",
    "    sommet_exist = [0] * (max(list(graph.keys())) + 1)\n",
    "    density = list()\n",
    "    for s in subgraph:\n",
    "        sommet_exist[s[0]] = 1\n",
    "        for v in graph[s[0]]:\n",
    "            if sommet_exist[v] == 1:\n",
    "                nb_edge = nb_edge + 1\n",
    "        if(len(density) == 0):\n",
    "            density.append(nb_edge)\n",
    "        else:\n",
    "            d = len(density)\n",
    "            density.append(nb_edge/d) \n",
    "    return density\n",
    "\n",
    "def get_edge_density(graph,file):\n",
    "    nbedge = nb_edge(file)\n",
    "    return nbedge / (max(graph.keys()) * (max(graph.keys()) - 1))\n",
    "\n",
    "def get_size_densest(density):\n",
    "    return density.index(max(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"graph/email/email-Eu-core.txt\"\n",
    "graph = email\n",
    "\n",
    "subgraph_order = core_decomposition(graph)\n",
    "subgraph = get_subgraph_ssj(graph)\n",
    "density = get_density(graph,subgraph)\n",
    "edge_density = get_edge_density(graph,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import heapq\n",
    "\n",
    "def core_decomposition_lst(graph):\n",
    "    c = 0\n",
    "    n = len(list(graph.keys())) + 1\n",
    "    coresDegrees = dict()\n",
    "    tas = BinHeap()\n",
    "    map_index_tas = dict()\n",
    "    visited = dict()\n",
    "    \n",
    "    for s in list(graph.keys()):\n",
    "        tas.insert((s,len(graph[s])),map_index_tas)\n",
    "        visited[s] = False\n",
    "\n",
    "    for i, t in enumerate(tas.heapList):\n",
    "        map_index_tas[t[0]] = i\n",
    "        \n",
    "    while(len(tas.heapList) > 0):\n",
    "        v = tas.heapList[0]\n",
    "        c = max(c,v[1])\n",
    "        \n",
    "        for v_voisin in graph[v[0]]:\n",
    "            if(visited[v_voisin] == True):\n",
    "                continue\n",
    "            v_voisin = int(v_voisin)\n",
    "            lst = list(tas.heapList[map_index_tas[v_voisin]])\n",
    "            lst[1] = tas.heapList[map_index_tas[v_voisin]][1] - 1\n",
    "            t = tuple(lst)\n",
    "            tas.heapList[map_index_tas[v_voisin]] = t\n",
    "            tas.percUp(map_index_tas[v_voisin],map_index_tas)\n",
    "        tas.delMin(map_index_tas)\n",
    "        visited[v[0]] = True\n",
    "        coresDegrees[v[0]] = (len(graph[v[0]]),c)\n",
    "    return coresDegrees\n",
    "\n",
    "clear_dataset(\"scholar/\",\"net.txt\",\" \")\n",
    "scholar = liste_adjacence(\"scholar/\")\n",
    "\n",
    "core_degree = dict()\n",
    "core_degree = core_decomposition_lst(scholar)\n",
    "\n",
    "degrees = list()\n",
    "kcores = list()\n",
    "\n",
    "for k,v in core_degree.items():\n",
    "    degrees.insert(k, v[0])\n",
    "    kcores.insert(k, v[1])\n",
    "\n",
    "plt.scatter(degrees,kcores)\n",
    "plt.title('net.txt')\n",
    "plt.xlabel('Degrees')\n",
    "plt.ylabel('Coreness')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = list()\n",
    "for d in range(len(degrees)):\n",
    "    if(kcores[d] == 14):\n",
    "        print(\"anomaly 1 : \" + str(d))\n",
    "        anomalies.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de la map r qui associe un noeud à son score\n",
    "def init_r(file, separator):\n",
    "    cleaned_graph = open(file, \"r\")\n",
    "    max_int = -1\n",
    "    for e in cleaned_graph:\n",
    "        if e.startswith(\"#\"):\n",
    "            continue\n",
    "        e = e.rstrip(\"\\n\")\n",
    "        indice_point = e.split(separator)\n",
    "        if int(indice_point[0])>max_int:\n",
    "            max_int = int(indice_point[0])\n",
    "        if int(indice_point[1])>max_int:\n",
    "            max_int = int(indice_point[1])\n",
    "    cleaned_graph.close()\n",
    "\n",
    "    r = dict()\n",
    "    for i in range(max_int+1):\n",
    "        r[i] = 0\n",
    "        \n",
    "    return r\n",
    "\n",
    "# Compute density score\n",
    "def MKscore(file,t, separator):\n",
    "    r = init_r(file, separator)\n",
    "    cleaned_graph = open(file, \"r\")\n",
    "    for time in range(t):\n",
    "        for e in cleaned_graph:\n",
    "            if e.startswith(\"#\"):\n",
    "                continue\n",
    "            edge_str = e.rstrip(\"\\n\")\n",
    "            edge = edge_str.split(separator)\n",
    "            i = int(edge[0])\n",
    "            j = int(edge[1])\n",
    "            if r[i] <= r[j]:\n",
    "                r[i] = r[i] + 1\n",
    "            else:\n",
    "                r[j] = r[j] + 1\n",
    "                \n",
    "    for k in r:\n",
    "        r[k] = r[k]/t\n",
    "        \n",
    "    cleaned_graph.close()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=10\n",
    "separator = \" \"\n",
    "result = MKscore(\"graph/email/email-Eu-core.txt\",iteration,separator)\n",
    "maximum = max(result, key=result.get)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
